{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UID Metadata Tracking\n",
    "\n",
    "By Kyle Baacke\n",
    "2/21/2022\n",
    "\n",
    "## Description:\n",
    "   There are at least as many naming conventions for files as there are researchers. Contrary to most naming conventions using abbreviations stringed together, this snippet describes a way to track as many researcher degrees of freedom (analysis metadata) as you would like, without lengthening the file name. Instead of attaching this metadata information to each file by embedding the information in the file name, the prefix or suffix on the file name is a unique identifier \\{UID\\} that points to a separate metadata file. This metadata file (\\{UID\\}_metadata.json) can contain as many key, value pairs as you want for any given pipeline. This removes any enticement to limit the number of metadata attributes saved on each run, further enabling reproducibility through clarity in analytic choices.\n",
    "\n",
    "## Helpful Links:\n",
    "    https://www.geeksforgeeks.org/read-json-file-using-python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import json\n",
    "import hashlib\n",
    "import os\n",
    "import pandas as pd\n",
    "# Get the file delimiter for the OS you are working on\n",
    "sep = os.path.sep\n",
    "# Get the folder containing your python script\n",
    "source_path = 'S:\\\\Code\\\\Helpful-Snippets\\\\Snippets\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Generate metadata dictionary\n",
    "\n",
    "Your metadata will initially be stored as a python dictionary containing key, value pairs. The objects can be base python classes like strings, lists, integers, and bools. Do not use Pandas DataFrame objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "  'atlas_name':'Schaefer2018_200Parcels_7Networks_order_FSLMNI152_2mm',\n",
    "  'confounds': [\n",
    "    \"Movement_RelativeRMS\",\n",
    "    \"trans_x_dt\", \"trans_y_dt\", \"trans_z_dt\",\n",
    "    \"rot_x_dt\", \"rot_y_dt\", \"rot_z_dt\",\n",
    "    \"trans_dx_dt\", \"trans_dy_dt\", \"trans_dz_dt\",\n",
    "    \"rot_dx_dt\", \"rot_dy_dt\", \"rot_dz_dt\"\n",
    "  ],\n",
    "  'n_parcels':200,\n",
    "  'smoothed':False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add values to the dictionary after it has been created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'atlas_name': 'Schaefer2018_200Parcels_7Networks_order_FSLMNI152_2mm', 'confounds': ['Movement_RelativeRMS', 'trans_x_dt', 'trans_y_dt', 'trans_z_dt', 'rot_x_dt', 'rot_y_dt', 'rot_z_dt', 'trans_dx_dt', 'trans_dy_dt', 'trans_dz_dt', 'rot_dx_dt', 'rot_dy_dt', 'rot_dz_dt'], 'n_parcels': 200, 'smoothed': False, 'Note': 'This is an additional note'}\n"
     ]
    }
   ],
   "source": [
    "metadata['Note'] = 'This is an additional note'\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Generate the unique identifier for the run\n",
    "\n",
    "Once you have settled on the metadata that you will use for that run, you can use the metadaa to generate a unique ID (UID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhash = hashlib.md5()\n",
    "encoded = json.dumps(metadata, sort_keys=True).encode()\n",
    "dhash.update(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the 8 value to change the number of characters in the unique ID via truncation. This ID is procedurally generated based on the metadata dictionary provided. If you input the same metadata, you will get the same run_uid from this function every time. Any changes to the dictionary will result in a new, unique identifier. Saving 8 characters keeps the ID short while still maintaining a low likelihood of duplicate IDs (4,294,967,296 possible values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b13c3d8b\n"
     ]
    }
   ],
   "source": [
    "run_uid = dhash.hexdigest()[:8]\n",
    "print(run_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Save metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:\\Code\\Helpful-Snippets\\Snippets\\b13c3d8b_metadata.json\n"
     ]
    }
   ],
   "source": [
    "with open(f'{source_path}{run_uid}_metadata.json', 'w') as outfile:\n",
    "  json.dump(metadata, outfile)\n",
    "print(f'{source_path}{run_uid}_metadata.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Make a folder specific to each output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:\\Code\\Helpful-Snippets\\Snippets\\Output\\b13c3d8b\\\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  out_dir = f'{source_path}Output{sep}{run_uid}{sep}'\n",
    "  os.makedirs(out_dir)\n",
    "except:\n",
    "  # Folder may already exist\n",
    "  pass\n",
    "# Now, when you save any output, you can save it to the 'out_dir' directory.\n",
    "print(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you can save individual files with the unique identifier by including the run_uid in the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_output = pd.DataFrame()\n",
    "dummy_output.to_csv(f'{out_dir}{run_uid}_empty_csv_example.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Programatically read in the metadata file\n",
    "\n",
    "In addition to being able to read the metadata json objects in any text editor (e.g. notepad), you can also read the information in when using the output from an analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'atlas_name': 'Schaefer2018_200Parcels_7Networks_order_FSLMNI152_2mm', 'confounds': ['Movement_RelativeRMS', 'trans_x_dt', 'trans_y_dt', 'trans_z_dt', 'rot_x_dt', 'rot_y_dt', 'rot_z_dt', 'trans_dx_dt', 'trans_dy_dt', 'trans_dz_dt', 'rot_dx_dt', 'rot_dy_dt', 'rot_dz_dt'], 'n_parcels': 200, 'smoothed': False, 'Note': 'This is an additional note'}\n",
      "Schaefer2018_200Parcels_7Networks_order_FSLMNI152_2mm\n"
     ]
    }
   ],
   "source": [
    "metadata_2 = json.load(open(f'{source_path}{run_uid}_metadata.json'))\n",
    "print(metadata_2)\n",
    "print(metadata_2['atlas_name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "8a9165a38afef2ca63a793efc4b24bbf7f99f4e695b0f158539651a5958eadc2"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}